{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header_cell"
   },
   "source": [
    "# AlgoSpace MARL Training Master Notebook for Google Colab Pro\n",
    "\n",
    "This notebook implements the complete Multi-Agent Reinforcement Learning (MARL) training pipeline optimized for Google Colab Pro's 24-hour GPU sessions.\n",
    "\n",
    "## Key Features:\n",
    "- Automatic GPU setup and verification\n",
    "- Google Drive integration for data and checkpoints\n",
    "- Session management with automatic recovery\n",
    "- Memory optimization for long training runs\n",
    "- Weights & Biases integration for monitoring\n",
    "- Production model export\n",
    "\n",
    "## Requirements:\n",
    "- Google Colab Pro subscription\n",
    "- Google Drive with sufficient storage (>50GB)\n",
    "- W&B account (optional but recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_title"
   },
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Warning: Not running in Google Colab. Some features may not work.\")\n",
    "\n",
    "# GPU verification\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"üíæ GPU Memory: {gpu_memory:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"‚ùå No GPU available. Training will be slow.\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "!pip install -q h5py pyyaml tqdm\n",
    "!pip install -q wandb tensorboard mlflow\n",
    "!pip install -q optuna scikit-learn\n",
    "!pip install -q gputil psutil\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    \n",
    "    # Set up project paths\n",
    "    DRIVE_BASE = \"/content/drive/MyDrive/AlgoSpace\"\n",
    "    !mkdir -p {DRIVE_BASE}/{data,checkpoints,models,results,logs}\n",
    "    \n",
    "    print(f\"‚úÖ Google Drive mounted at {DRIVE_BASE}\")\n",
    "else:\n",
    "    DRIVE_BASE = \"./drive_simulation\"\n",
    "    import os\n",
    "    os.makedirs(DRIVE_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone AlgoSpace repository\n",
    "import os\n",
    "import sys\n",
    "\n",
    "REPO_PATH = \"/content/AlgoSpace\"\n",
    "if not os.path.exists(REPO_PATH):\n",
    "    !git clone https://github.com/QuantNova/AlgoSpace.git {REPO_PATH}\n",
    "    print(\"‚úÖ Repository cloned\")\n",
    "else:\n",
    "    # Pull latest changes\n",
    "    !cd {REPO_PATH} && git pull\n",
    "    print(\"‚úÖ Repository updated\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, REPO_PATH)\n",
    "sys.path.insert(0, os.path.join(REPO_PATH, 'src'))\n",
    "sys.path.insert(0, os.path.join(REPO_PATH, 'notebooks'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_utils_title"
   },
   "source": [
    "## 2. Load Colab Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_utils"
   },
   "outputs": [],
   "source": [
    "# Import Colab utilities\n",
    "from notebooks.utils.colab_setup import ColabSetup, SessionMonitor, setup_colab_training\n",
    "from notebooks.utils.drive_manager import DriveManager, DataStreamer\n",
    "from notebooks.utils.checkpoint_manager import CheckpointManager, CheckpointScheduler\n",
    "\n",
    "# Initialize setup\n",
    "setup = ColabSetup(\"AlgoSpace\")\n",
    "drive_manager = DriveManager(DRIVE_BASE)\n",
    "checkpoint_manager = CheckpointManager(drive_manager)\n",
    "session_monitor = SessionMonitor(max_runtime_hours=23.5)  # 30 min buffer\n",
    "\n",
    "print(\"‚úÖ Utilities loaded\")\n",
    "print(\"\\nüìä System Information:\")\n",
    "system_info = setup.get_system_info()\n",
    "for key, value in system_info.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"\\n{key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keep_alive"
   },
   "outputs": [],
   "source": [
    "# Activate keep-alive to prevent session timeout\n",
    "if IN_COLAB:\n",
    "    setup.keep_alive()\n",
    "    print(\"‚úÖ Keep-alive activated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_title"
   },
   "source": [
    "## 3. Load Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_config"
   },
   "outputs": [],
   "source": [
    "# Load training configuration\n",
    "import yaml\n",
    "\n",
    "config_path = os.path.join(REPO_PATH, 'config/training_config.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Adjust for Colab environment\n",
    "config['training']['checkpoint_frequency'] = 100  # More frequent checkpoints\n",
    "config['training']['validation_frequency'] = 50\n",
    "config['training']['batch_size'] = 256  # Adjust based on GPU\n",
    "config['training']['gradient_accumulation_steps'] = 4\n",
    "config['training']['mixed_precision'] = True\n",
    "\n",
    "# Session management\n",
    "config['colab'] = {\n",
    "    'auto_save_to_drive': True,\n",
    "    'resume_from_checkpoint': True,\n",
    "    'memory_optimization': True,\n",
    "    'keep_alive_interval': 300,  # 5 minutes\n",
    "    'checkpoint_on_interrupt': True\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"- Total Episodes: {config['training']['num_episodes']}\")\n",
    "print(f\"- Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"- Learning Rate: {config['training']['learning_rate']}\")\n",
    "print(f\"- Checkpoint Frequency: {config['training']['checkpoint_frequency']} episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wandb_title"
   },
   "source": [
    "## 4. Setup Experiment Tracking (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_wandb"
   },
   "outputs": [],
   "source": [
    "# Setup Weights & Biases (optional but recommended)\n",
    "USE_WANDB = True  # Set to False if you don't want to use W&B\n",
    "\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    \n",
    "    # Login to W&B (you'll need to enter your API key)\n",
    "    wandb.login()\n",
    "    \n",
    "    # Initialize W&B run\n",
    "    run = wandb.init(\n",
    "        project=\"algospace-marl-training\",\n",
    "        config=config,\n",
    "        name=f\"marl_training_{session_monitor.start_time.strftime('%Y%m%d_%H%M%S')}\",\n",
    "        resume=\"allow\",\n",
    "        id=checkpoint_manager.get_resume_info().get('wandb_id', None)\n",
    "    )\n",
    "    \n",
    "    # Log system info\n",
    "    wandb.config.update(system_info)\n",
    "    \n",
    "    print(f\"‚úÖ W&B initialized: {run.url}\")\n",
    "else:\n",
    "    run = None\n",
    "    print(\"‚ÑπÔ∏è W&B disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_title"
   },
   "source": [
    "## 5. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_data"
   },
   "outputs": [],
   "source": [
    "# Check available data\n",
    "available_data = drive_manager.list_available('data')\n",
    "print(\"üìÇ Available datasets:\")\n",
    "for dataset in available_data.get('data', []):\n",
    "    info = drive_manager.get_info(dataset, 'data')\n",
    "    size_mb = info.get('size', 0) / 1e6\n",
    "    print(f\"- {dataset}: {size_mb:.2f} MB\")\n",
    "\n",
    "# If no data, provide upload instructions\n",
    "if not available_data.get('data'):\n",
    "    print(\"\\n‚ö†Ô∏è No training data found. Please upload data to:\")\n",
    "    print(f\"   {DRIVE_BASE}/data/\")\n",
    "    print(\"\\nExpected format: HDF5 files with market data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "from training.data_prep import MarketDataPipeline, DataLoader\n",
    "\n",
    "# Initialize data pipeline\n",
    "data_pipeline = MarketDataPipeline(config['data'])\n",
    "\n",
    "# Load or download data\n",
    "DATASET_NAME = \"market_data_2023\"  # Change to your dataset name\n",
    "if DATASET_NAME in available_data.get('data', []):\n",
    "    # Download from Drive to local temp\n",
    "    local_data_path = drive_manager.download_data(DATASET_NAME, decompress=True)\n",
    "    print(f\"‚úÖ Data loaded from Drive: {local_data_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found. Using sample data...\")\n",
    "    # Create sample data for testing\n",
    "    local_data_path = \"/tmp/sample_data.h5\"\n",
    "    data_pipeline.create_sample_data(local_data_path)\n",
    "\n",
    "# Create data loader with efficient streaming\n",
    "data_streamer = DataStreamer(\n",
    "    local_data_path,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    cache_size=1000\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loader initialized\")\n",
    "print(f\"   Total samples: {len(data_streamer.h5_file['features'])}\")\n",
    "print(f\"   Batch size: {data_streamer.batch_size}\")\n",
    "print(f\"   Number of batches: {len(data_streamer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_title"
   },
   "source": [
    "## 6. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_models"
   },
   "outputs": [],
   "source": [
    "# Import model components\n",
    "from agents.regime_detector import RegimeDetector\n",
    "from agents.structure_analyzer import MarketStructureAnalyzer\n",
    "from agents.tactical_trader import TacticalTrader\n",
    "from agents.risk_manager import RiskManager\n",
    "from coordination.multi_agent_coordinator import MultiAgentCoordinator\n",
    "\n",
    "# Import training components\n",
    "from training.marl_trainer import MAPPOTrainer\n",
    "from training.environment import MultiAgentTradingEnv\n",
    "from training.rewards import MultiAgentRewardSystem\n",
    "from training.experience import ExperienceBuffer\n",
    "\n",
    "print(\"‚úÖ Model components imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_resume"
   },
   "outputs": [],
   "source": [
    "# Check if we can resume from checkpoint\n",
    "resume_info = checkpoint_manager.get_resume_info()\n",
    "\n",
    "if resume_info['available']:\n",
    "    print(\"üìÇ Checkpoint found!\")\n",
    "    print(f\"   Episode: {resume_info['episode']}\")\n",
    "    print(f\"   Hours since save: {resume_info.get('hours_since_save', 0):.2f}\")\n",
    "    print(f\"   Metrics: {resume_info.get('metrics', {})}\")\n",
    "    \n",
    "    # Ask user if they want to resume\n",
    "    if IN_COLAB:\n",
    "        resume = input(\"Resume from checkpoint? (y/n): \").lower() == 'y'\n",
    "    else:\n",
    "        resume = True  # Auto-resume in non-interactive mode\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No checkpoint found. Starting fresh training.\")\n",
    "    resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_models"
   },
   "outputs": [],
   "source": [
    "# Initialize or load models\n",
    "if resume and resume_info['available']:\n",
    "    # Load from checkpoint\n",
    "    print(\"\\nüìÇ Loading checkpoint...\")\n",
    "    checkpoint = checkpoint_manager.load_latest()\n",
    "    \n",
    "    # Restore state\n",
    "    state = checkpoint['state']\n",
    "    start_episode = state['episode']\n",
    "    \n",
    "    # Initialize agents with saved state\n",
    "    agents = {}\n",
    "    for agent_name, agent_state in state['models'].items():\n",
    "        if agent_name == 'regime_detector':\n",
    "            agent = RegimeDetector(config['agents']['regime_detector'])\n",
    "        elif agent_name == 'structure_analyzer':\n",
    "            agent = MarketStructureAnalyzer(config['agents']['structure_analyzer'])\n",
    "        elif agent_name == 'tactical_trader':\n",
    "            agent = TacticalTrader(config['agents']['tactical_trader'])\n",
    "        elif agent_name == 'risk_manager':\n",
    "            agent = RiskManager(config['agents']['risk_manager'])\n",
    "        \n",
    "        agent.load_state_dict(agent_state)\n",
    "        agent.to(device)\n",
    "        agents[agent_name] = agent\n",
    "    \n",
    "    # Initialize coordinator\n",
    "    coordinator = MultiAgentCoordinator(config['coordinator'])\n",
    "    coordinator.agents = agents\n",
    "    \n",
    "    print(\"‚úÖ Models loaded from checkpoint\")\n",
    "    \n",
    "else:\n",
    "    # Initialize fresh models\n",
    "    print(\"\\nüî® Initializing new models...\")\n",
    "    start_episode = 0\n",
    "    \n",
    "    # Initialize agents\n",
    "    agents = {\n",
    "        'regime_detector': RegimeDetector(config['agents']['regime_detector']).to(device),\n",
    "        'structure_analyzer': MarketStructureAnalyzer(config['agents']['structure_analyzer']).to(device),\n",
    "        'tactical_trader': TacticalTrader(config['agents']['tactical_trader']).to(device),\n",
    "        'risk_manager': RiskManager(config['agents']['risk_manager']).to(device)\n",
    "    }\n",
    "    \n",
    "    # Initialize coordinator\n",
    "    coordinator = MultiAgentCoordinator(config['coordinator'])\n",
    "    coordinator.agents = agents\n",
    "    \n",
    "    print(\"‚úÖ Models initialized\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(sum(p.numel() for p in agent.parameters()) for agent in agents.values())\n",
    "print(f\"\\nüìä Total parameters: {total_params:,}\")\n",
    "for name, agent in agents.items():\n",
    "    params = sum(p.numel() for p in agent.parameters())\n",
    "    print(f\"   {name}: {params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_title"
   },
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_training"
   },
   "outputs": [],
   "source": [
    "# Initialize training environment\n",
    "env = MultiAgentTradingEnv(config['environment'])\n",
    "reward_system = MultiAgentRewardSystem(config['rewards'])\n",
    "experience_buffer = ExperienceBuffer(\n",
    "    capacity=config['training']['buffer_size'],\n",
    "    prioritized=config['training'].get('prioritized_replay', True)\n",
    ")\n",
    "\n",
    "# Initialize MAPPO trainer\n",
    "trainer = MAPPOTrainer(\n",
    "    agents=agents,\n",
    "    coordinator=coordinator,\n",
    "    env=env,\n",
    "    config=config['training'],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Set up optimizers\n",
    "if resume and resume_info['available']:\n",
    "    # Restore optimizer states\n",
    "    for name, optimizer_state in state.get('optimizers', {}).items():\n",
    "        if hasattr(trainer, f'{name}_optimizer'):\n",
    "            getattr(trainer, f'{name}_optimizer').load_state_dict(optimizer_state)\n",
    "\n",
    "print(\"‚úÖ Training environment initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "memory_optimization"
   },
   "outputs": [],
   "source": [
    "# Memory optimization settings\n",
    "if config['colab']['memory_optimization']:\n",
    "    # Enable gradient checkpointing\n",
    "    for agent in agents.values():\n",
    "        if hasattr(agent, 'enable_gradient_checkpointing'):\n",
    "            agent.enable_gradient_checkpointing()\n",
    "    \n",
    "    # Set memory fraction\n",
    "    torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "    \n",
    "    # Enable mixed precision training\n",
    "    from torch.cuda.amp import GradScaler\n",
    "    scaler = GradScaler() if config['training']['mixed_precision'] else None\n",
    "    \n",
    "    print(\"‚úÖ Memory optimization enabled\")\n",
    "    print(f\"   Current GPU memory: {setup.check_gpu_memory()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_loop_title"
   },
   "source": [
    "## 8. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_functions"
   },
   "outputs": [],
   "source": [
    "# Training helper functions\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_checkpoint(episode, metrics, is_best=False):\n",
    "    \"\"\"Save training checkpoint\"\"\"\n",
    "    state = {\n",
    "        'episode': episode,\n",
    "        'models': {name: agent.state_dict() for name, agent in agents.items()},\n",
    "        'optimizers': {name: opt.state_dict() for name, opt in trainer.optimizers.items()},\n",
    "        'metrics': metrics,\n",
    "        'config': config,\n",
    "        'wandb_id': run.id if run else None\n",
    "    }\n",
    "    \n",
    "    checkpoint_manager.save(state, metrics, is_best=is_best)\n",
    "    print(f\"üíæ Checkpoint saved (episode {episode})\")\n",
    "\n",
    "def plot_training_progress(history):\n",
    "    \"\"\"Plot training metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Plot rewards\n",
    "    axes[0, 0].plot(history['episode'], history['reward'])\n",
    "    axes[0, 0].set_title('Episode Reward')\n",
    "    axes[0, 0].set_xlabel('Episode')\n",
    "    axes[0, 0].set_ylabel('Reward')\n",
    "    \n",
    "    # Plot Sharpe ratio\n",
    "    axes[0, 1].plot(history['episode'], history['sharpe_ratio'])\n",
    "    axes[0, 1].set_title('Sharpe Ratio')\n",
    "    axes[0, 1].set_xlabel('Episode')\n",
    "    axes[0, 1].set_ylabel('Sharpe')\n",
    "    \n",
    "    # Plot win rate\n",
    "    axes[1, 0].plot(history['episode'], history['win_rate'])\n",
    "    axes[1, 0].set_title('Win Rate')\n",
    "    axes[1, 0].set_xlabel('Episode')\n",
    "    axes[1, 0].set_ylabel('Win Rate (%)')\n",
    "    \n",
    "    # Plot drawdown\n",
    "    axes[1, 1].plot(history['episode'], history['max_drawdown'])\n",
    "    axes[1, 1].set_title('Maximum Drawdown')\n",
    "    axes[1, 1].set_xlabel('Episode')\n",
    "    axes[1, 1].set_ylabel('Drawdown (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def should_stop_training(metrics, patience=50):\n",
    "    \"\"\"Check if training should stop\"\"\"\n",
    "    # Check if session is ending soon\n",
    "    if session_monitor.is_ending_soon(buffer_minutes=20):\n",
    "        return True, \"Session ending soon\"\n",
    "    \n",
    "    # Check if target performance reached\n",
    "    if metrics.get('sharpe_ratio', 0) > 1.2 and metrics.get('win_rate', 0) > 0.52:\n",
    "        return True, \"Target performance reached\"\n",
    "    \n",
    "    return False, \"\"\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_training_loop"
   },
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(f\"   Starting from episode: {start_episode}\")\n",
    "print(f\"   Total episodes: {config['training']['num_episodes']}\")\n",
    "print(f\"   Session time remaining: {session_monitor.get_remaining_time()['remaining_hours']:.1f} hours\\n\")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'episode': [],\n",
    "    'reward': [],\n",
    "    'sharpe_ratio': [],\n",
    "    'win_rate': [],\n",
    "    'max_drawdown': []\n",
    "}\n",
    "\n",
    "# Best metrics tracking\n",
    "best_sharpe = -float('inf')\n",
    "episodes_since_best = 0\n",
    "\n",
    "# Training loop\n",
    "try:\n",
    "    for episode in range(start_episode, config['training']['num_episodes']):\n",
    "        episode_start = time.time()\n",
    "        \n",
    "        # Run training episode\n",
    "        episode_metrics = trainer.train_episode(episode)\n",
    "        \n",
    "        # Update history\n",
    "        history['episode'].append(episode)\n",
    "        history['reward'].append(episode_metrics['total_reward'])\n",
    "        history['sharpe_ratio'].append(episode_metrics.get('sharpe_ratio', 0))\n",
    "        history['win_rate'].append(episode_metrics.get('win_rate', 0))\n",
    "        history['max_drawdown'].append(episode_metrics.get('max_drawdown', 0))\n",
    "        \n",
    "        # Check if best model\n",
    "        current_sharpe = episode_metrics.get('sharpe_ratio', 0)\n",
    "        is_best = current_sharpe > best_sharpe\n",
    "        if is_best:\n",
    "            best_sharpe = current_sharpe\n",
    "            episodes_since_best = 0\n",
    "        else:\n",
    "            episodes_since_best += 1\n",
    "        \n",
    "        # Log to W&B\n",
    "        if run:\n",
    "            wandb.log(episode_metrics, step=episode)\n",
    "        \n",
    "        # Checkpoint saving\n",
    "        checkpoint_scheduler = CheckpointScheduler(checkpoint_manager)\n",
    "        should_checkpoint, reason = checkpoint_scheduler.should_checkpoint(episode, episode_metrics)\n",
    "        \n",
    "        if should_checkpoint or is_best:\n",
    "            save_checkpoint(episode, episode_metrics, is_best=is_best)\n",
    "            checkpoint_scheduler.update_schedule(episode, episode_metrics, saved=True)\n",
    "        \n",
    "        # Memory optimization\n",
    "        if episode % 10 == 0:\n",
    "            setup.optimize_memory()\n",
    "        \n",
    "        # Progress display\n",
    "        if episode % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Display metrics\n",
    "            print(f\"üìä Episode {episode}/{config['training']['num_episodes']}\")\n",
    "            print(f\"   Reward: {episode_metrics['total_reward']:.4f}\")\n",
    "            print(f\"   Sharpe Ratio: {current_sharpe:.4f} (Best: {best_sharpe:.4f})\")\n",
    "            print(f\"   Win Rate: {episode_metrics.get('win_rate', 0)*100:.1f}%\")\n",
    "            print(f\"   Max Drawdown: {episode_metrics.get('max_drawdown', 0)*100:.1f}%\")\n",
    "            print(f\"   Episode Time: {time.time() - episode_start:.1f}s\")\n",
    "            print(f\"   Session Time Remaining: {session_monitor.get_remaining_time()['remaining_hours']:.1f}h\")\n",
    "            print(f\"   GPU Memory: {setup.check_gpu_memory()['allocated']:.1f}GB / {setup.check_gpu_memory()['free']:.1f}GB free\")\n",
    "            \n",
    "            # Plot progress\n",
    "            if len(history['episode']) > 20:\n",
    "                fig = plot_training_progress(history)\n",
    "                plt.show()\n",
    "                \n",
    "                # Save plot to drive\n",
    "                plot_path = f\"{DRIVE_BASE}/results/training_progress_ep{episode}.png\"\n",
    "                fig.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        \n",
    "        # Check stopping criteria\n",
    "        should_stop, stop_reason = should_stop_training(episode_metrics)\n",
    "        if should_stop:\n",
    "            print(f\"\\nüõë Stopping training: {stop_reason}\")\n",
    "            save_checkpoint(episode, episode_metrics, is_best=True)\n",
    "            break\n",
    "        \n",
    "        # Validation\n",
    "        if episode % config['training']['validation_frequency'] == 0 and episode > 0:\n",
    "            print(\"\\nüîç Running validation...\")\n",
    "            val_metrics = trainer.validate()\n",
    "            print(f\"   Validation Sharpe: {val_metrics.get('sharpe_ratio', 0):.4f}\")\n",
    "            print(f\"   Validation Win Rate: {val_metrics.get('win_rate', 0)*100:.1f}%\")\n",
    "            \n",
    "            if run:\n",
    "                wandb.log({f\"val/{k}\": v for k, v in val_metrics.items()}, step=episode)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    save_checkpoint(episode, episode_metrics, is_best=False)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training error: {e}\")\n",
    "    save_checkpoint(episode, episode_metrics, is_best=False)\n",
    "    raise\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_title"
   },
   "source": [
    "## 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_evaluation"
   },
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "print(\"üìÇ Loading best model for evaluation...\")\n",
    "best_checkpoint = checkpoint_manager.load(load_best=True)\n",
    "\n",
    "# Restore best model states\n",
    "for name, agent in agents.items():\n",
    "    agent.load_state_dict(best_checkpoint['state']['models'][name])\n",
    "    agent.eval()\n",
    "\n",
    "print(\"‚úÖ Best model loaded\")\n",
    "print(f\"   Episode: {best_checkpoint['state']['episode']}\")\n",
    "print(f\"   Metrics: {best_checkpoint['metrics']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comprehensive_evaluation"
   },
   "outputs": [],
   "source": [
    "# Comprehensive evaluation\n",
    "from training.monitoring import ModelEvaluator, BacktestEngine\n",
    "\n",
    "evaluator = ModelEvaluator(config['evaluation'])\n",
    "backtest_engine = BacktestEngine(config['backtest'])\n",
    "\n",
    "print(\"\\nüîç Running comprehensive evaluation...\")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_results = evaluator.evaluate_models(\n",
    "    agents=agents,\n",
    "    coordinator=coordinator,\n",
    "    test_data=data_streamer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Run backtest\n",
    "backtest_results = backtest_engine.run_backtest(\n",
    "    agents=agents,\n",
    "    coordinator=coordinator,\n",
    "    historical_data=data_streamer\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä Evaluation Results:\")\n",
    "print(f\"   Test Sharpe Ratio: {test_results['sharpe_ratio']:.4f}\")\n",
    "print(f\"   Test Win Rate: {test_results['win_rate']*100:.1f}%\")\n",
    "print(f\"   Test Max Drawdown: {test_results['max_drawdown']*100:.1f}%\")\n",
    "print(f\"   Average Trade Return: {test_results['avg_return']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nüìà Backtest Results:\")\n",
    "print(f\"   Total Return: {backtest_results['total_return']*100:.2f}%\")\n",
    "print(f\"   Annualized Return: {backtest_results['annualized_return']*100:.2f}%\")\n",
    "print(f\"   Sharpe Ratio: {backtest_results['sharpe_ratio']:.4f}\")\n",
    "print(f\"   Calmar Ratio: {backtest_results['calmar_ratio']:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "drive_manager.save_results(\n",
    "    results={\n",
    "        'test_results': test_results,\n",
    "        'backtest_results': backtest_results,\n",
    "        'training_history': history,\n",
    "        'best_episode': best_checkpoint['state']['episode'],\n",
    "        'config': config\n",
    "    },\n",
    "    name=\"marl_evaluation\",\n",
    "    plots={'training_progress': plot_training_progress(history)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_title"
   },
   "source": [
    "## 10. Model Export for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_models"
   },
   "outputs": [],
   "source": [
    "# Export models for production\n",
    "print(\"üì¶ Exporting models for production...\")\n",
    "\n",
    "# Optimize models for inference\n",
    "production_models = {}\n",
    "for name, agent in agents.items():\n",
    "    agent.eval()\n",
    "    \n",
    "    # Convert to TorchScript\n",
    "    try:\n",
    "        scripted_model = torch.jit.script(agent)\n",
    "        production_models[f\"{name}_scripted\"] = scripted_model\n",
    "        print(f\"   ‚úÖ {name}: TorchScript conversion successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è {name}: TorchScript conversion failed - {e}\")\n",
    "        production_models[name] = agent\n",
    "\n",
    "# Save production models\n",
    "model_path = drive_manager.save_model(\n",
    "    models=agents,\n",
    "    name=\"marl_production\",\n",
    "    configs=config,\n",
    "    metrics=best_checkpoint['metrics'],\n",
    "    production=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Models exported to: {model_path}\")\n",
    "\n",
    "# Create deployment package\n",
    "package_path = drive_manager.create_training_package(\"marl_deployment_package\")\n",
    "print(f\"‚úÖ Deployment package created: {package_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_title"
   },
   "source": [
    "## 11. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_summary"
   },
   "outputs": [],
   "source": [
    "# Create training summary\n",
    "summary = f\"\"\"\n",
    "# AlgoSpace MARL Training Summary\n",
    "\n",
    "## Training Details\n",
    "- Start Time: {session_monitor.start_time.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- Total Runtime: {session_monitor.get_runtime_hours():.2f} hours\n",
    "- Episodes Trained: {episode - start_episode}\n",
    "- Final Episode: {episode}\n",
    "\n",
    "## Best Model Performance\n",
    "- Episode: {best_checkpoint['state']['episode']}\n",
    "- Sharpe Ratio: {best_checkpoint['metrics'].get('sharpe_ratio', 0):.4f}\n",
    "- Win Rate: {best_checkpoint['metrics'].get('win_rate', 0)*100:.1f}%\n",
    "- Max Drawdown: {best_checkpoint['metrics'].get('max_drawdown', 0)*100:.1f}%\n",
    "\n",
    "## Test Performance\n",
    "- Test Sharpe: {test_results['sharpe_ratio']:.4f}\n",
    "- Test Win Rate: {test_results['win_rate']*100:.1f}%\n",
    "- Test Drawdown: {test_results['max_drawdown']*100:.1f}%\n",
    "\n",
    "## Backtest Performance\n",
    "- Total Return: {backtest_results['total_return']*100:.2f}%\n",
    "- Annualized Return: {backtest_results['annualized_return']*100:.2f}%\n",
    "- Sharpe Ratio: {backtest_results['sharpe_ratio']:.4f}\n",
    "\n",
    "## System Information\n",
    "- GPU: {system_info['gpu'].get('name', 'N/A')}\n",
    "- GPU Memory: {system_info['gpu'].get('memory_total', 'N/A')}\n",
    "- Peak GPU Usage: {max(h['allocated'] for h in [setup.check_gpu_memory()]):.1f}GB\n",
    "\n",
    "## Files Saved\n",
    "- Best Model: {model_path}\n",
    "- Deployment Package: {package_path}\n",
    "- Evaluation Results: {DRIVE_BASE}/results/\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary\n",
    "summary_path = f\"{DRIVE_BASE}/results/training_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\n‚úÖ Summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup"
   },
   "outputs": [],
   "source": [
    "# Cleanup and final steps\n",
    "if run:\n",
    "    # Finish W&B run\n",
    "    wandb.finish()\n",
    "\n",
    "# Close data connections\n",
    "data_streamer.close()\n",
    "\n",
    "# Final memory cleanup\n",
    "setup.optimize_memory()\n",
    "\n",
    "print(\"\\nüéâ Training pipeline completed successfully!\")\n",
    "print(\"\\nüìã Next Steps:\")\n",
    "print(\"1. Download the deployment package from Google Drive\")\n",
    "print(\"2. Review the evaluation results and training plots\")\n",
    "print(\"3. Test the production models in your deployment environment\")\n",
    "print(\"4. Consider running ensemble training with different seeds\")\n",
    "print(\"\\nThank you for using AlgoSpace MARL Training!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}